{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Embeddings models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx1PC5guOMN1",
        "colab_type": "text"
      },
      "source": [
        "## Downloads and imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmZCgch8MeXO",
        "colab_type": "code",
        "outputId": "dbb57aca-b1f7-4605-d1ac-6e03f4324539",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "from os.path import exists\n",
        "if not exists('ende_data.zip'):\n",
        "    !wget -O ende_data.zip https://competitions.codalab.org/my/datasets/download/c748d2c0-d6be-4e36-9f12-ca0e88819c4d\n",
        "    !unzip ende_data.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-28 14:34:20--  https://competitions.codalab.org/my/datasets/download/c748d2c0-d6be-4e36-9f12-ca0e88819c4d\n",
            "Resolving competitions.codalab.org (competitions.codalab.org)... 129.175.22.230\n",
            "Connecting to competitions.codalab.org (competitions.codalab.org)|129.175.22.230|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://newcodalab.lri.fr/prod-private/dataset_data_file/None/104ea/en-de.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=65d8a93719821b21d02e94c78f369043ee6775eabb83f0ebb6418b72c2296ae2&X-Amz-Date=20200228T143426Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20200228%2Fnewcodalab%2Fs3%2Faws4_request [following]\n",
            "--2020-02-28 14:34:26--  https://newcodalab.lri.fr/prod-private/dataset_data_file/None/104ea/en-de.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=65d8a93719821b21d02e94c78f369043ee6775eabb83f0ebb6418b72c2296ae2&X-Amz-Date=20200228T143426Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20200228%2Fnewcodalab%2Fs3%2Faws4_request\n",
            "Resolving newcodalab.lri.fr (newcodalab.lri.fr)... 129.175.15.11\n",
            "Connecting to newcodalab.lri.fr (newcodalab.lri.fr)|129.175.15.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 864010 (844K) [application/zip]\n",
            "Saving to: ‘ende_data.zip’\n",
            "\n",
            "ende_data.zip       100%[===================>] 843.76K  1.33MB/s    in 0.6s    \n",
            "\n",
            "2020-02-28 14:34:28 (1.33 MB/s) - ‘ende_data.zip’ saved [864010/864010]\n",
            "\n",
            "Archive:  ende_data.zip\n",
            "  inflating: dev.ende.mt             \n",
            "  inflating: dev.ende.scores         \n",
            "  inflating: dev.ende.src            \n",
            "  inflating: test.ende.mt            \n",
            "  inflating: test.ende.src           \n",
            "  inflating: train.ende.mt           \n",
            "  inflating: train.ende.scores       \n",
            "  inflating: train.ende.src          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiO5vIoTMjb8",
        "colab_type": "code",
        "outputId": "29c4967f-9a1c-4827-fb98-fe320c120e39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "!spacy download en_core_web_md\n",
        "!spacy link en_core_web_md en300\n",
        "\n",
        "!spacy download de_core_news_md\n",
        "!spacy link de_core_news_md de300"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_md==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.1.0/en_core_web_md-2.1.0.tar.gz (95.4MB)\n",
            "\u001b[K     |████████████████████████████████| 95.4MB 1.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-md\n",
            "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-md: filename=en_core_web_md-2.1.0-cp36-none-any.whl size=97126236 sha256=a4dd28bfed44a9179bac04806d04fd23fa3e60011c867c7459009f6fe889a4fa\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4z17tvmn/wheels/c1/2c/5f/fd7f3ec336bf97b0809c86264d2831c5dfb00fc2e239d1bb01\n",
            "Successfully built en-core-web-md\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_md -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en300\n",
            "You can now load the model via spacy.load('en300')\n",
            "Collecting de_core_news_md==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_md-2.1.0/de_core_news_md-2.1.0.tar.gz (220.8MB)\n",
            "\u001b[K     |████████████████████████████████| 220.8MB 1.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: de-core-news-md\n",
            "  Building wheel for de-core-news-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-md: filename=de_core_news_md-2.1.0-cp36-none-any.whl size=224546880 sha256=795343d4681220974190a49060a275cdb0f46b0c3877301f51c2110dd828a29f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-b1w1qbiw/wheels/44/34/f1/31d4b0fa32008c09695ccb180865f196ecd9d512c146f99749\n",
            "Successfully built de-core-news-md\n",
            "Installing collected packages: de-core-news-md\n",
            "Successfully installed de-core-news-md-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_md')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_md -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de300\n",
            "You can now load the model via spacy.load('de300')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0V-iLkMMnam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk4zDCBVMp9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp_de =spacy.load('de300')\n",
        "nlp_en =spacy.load('en300')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhXFm4zMMs9j",
        "colab_type": "code",
        "outputId": "7dc47627-4575-4f3a-fd54-a0d5f652fd86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from nltk import download\n",
        "from nltk.corpus import stopwords\n",
        "download('stopwords') #stopwords dictionary, run once\n",
        "\n",
        "stop_words_en = set(stopwords.words('english'))\n",
        "stop_words_de = set(stopwords.words('german'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugT1KZ8bmN2A",
        "colab_type": "code",
        "outputId": "d7e655c3-35e8-4473-ca2c-d76b3132d473",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "!pip install keras_self_attention"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras_self_attention\n",
            "  Downloading https://files.pythonhosted.org/packages/44/3e/eb1a7c7545eede073ceda2f5d78442b6cad33b5b750d7f0742866907c34b/keras-self-attention-0.42.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras_self_attention) (1.17.5)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_self_attention) (2.2.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_self_attention) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_self_attention) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras_self_attention) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_self_attention) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_self_attention) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras_self_attention) (3.13)\n",
            "Building wheels for collected packages: keras-self-attention\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.42.0-cp36-none-any.whl size=17296 sha256=d28606ad821e37b8fd6863a7d7d40191098e29e2227425d1066f905cc0e73a6f\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/05/a0/99c0cf60d383f0494e10eca2b238ea98faca9a1fe03cac2894\n",
            "Successfully built keras-self-attention\n",
            "Installing collected packages: keras-self-attention\n",
            "Successfully installed keras-self-attention-0.42.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEIiKN1NZaZT",
        "colab_type": "code",
        "outputId": "ebe005bd-cf6b-4ff6-cc81-67374180dbd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Embedding, LSTM, GRU, GlobalMaxPooling1D, SpatialDropout1D, Bidirectional, Flatten, Input, Concatenate\n",
        "from keras_self_attention import SeqSelfAttention\n",
        "import tensorflow as tf"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCqhqKbdZykn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import pearsonr "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bZpofILOw_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MpVnRoWSTIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMqxTqriTSr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmdMx1bXU2CK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFNfzv-PV-fk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmcFRhY_O4Pf",
        "colab_type": "text"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKbFFMY9MvA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embeddings(lines, nlp, stopwords, lang):\n",
        "  unknown = nlp.vocab['unk'].vector\n",
        "  punctuation = [',','.','...','\\'', '\"', '(', ')', '[', ']']\n",
        "  lines_embs = []\n",
        "  \n",
        "  documents = nlp.pipe(lines, batch_size=32, n_threads=7)\n",
        "  for doc in documents:\n",
        "    l = []\n",
        "    for token in doc:\n",
        "      if token.text in stopwords or token.text in punctuation:\n",
        "        continue\n",
        "      if not token.has_vector:\n",
        "        l.append(unknown)\n",
        "      else:\n",
        "        l.append(token.vector)\n",
        "    lines_embs.append(l)\n",
        "  return lines_embs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juczioIOjCk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sent(lst):\n",
        "    pad = 35 # maximum sentence length for train, validation and test data\n",
        "    arr = []\n",
        "    for i in lst:\n",
        "      arr.append(np.concatenate((i, ([np.zeros(300)] * (pad-len(i)))), axis=0))\n",
        "    return arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-M9CYmL1c8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converts scores file to list of floats\n",
        "def get_scores(f):\n",
        "  scores = open(f, 'r').readlines()\n",
        "  for i in range(len(scores)):\n",
        "    scores[i] = float(scores[i])\n",
        "  return scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_LFQtYztIXe",
        "colab_type": "text"
      },
      "source": [
        "## Shuffling and splitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZR910CQjU8pL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combines training and validation data, shuffles and splits to 8000 and 1000\n",
        "def shuffle_and_split():\n",
        "  train_f_en = open('./train.ende.src')\n",
        "  lines_train_en = train_f_en.readlines()\n",
        "  train_f_de = open('./train.ende.mt')\n",
        "  lines_train_de = train_f_de.readlines()\n",
        "  val_f_en = open('./dev.ende.src')\n",
        "  lines_val_en = val_f_en.readlines()\n",
        "  val_f_de = open('./dev.ende.mt')\n",
        "  lines_val_de = val_f_de.readlines()\n",
        "\n",
        "  data = []\n",
        "  for i in range(len(lines_train_en)):\n",
        "    data.append((lines_train_en[i], lines_train_de[i]))\n",
        "  \n",
        "  for i in range(len(lines_val_en)):\n",
        "    data.append((lines_val_en[i], lines_val_de[i]))\n",
        "\n",
        "  scores = get_scores('./train.ende.scores')\n",
        "  scores = scores + get_scores('./dev.ende.scores')\n",
        "\n",
        "  X_train, X_val, y_train, y_val = train_test_split(data, scores, train_size=0.875, random_state=42, shuffle=True)\n",
        "\n",
        "  return X_train, X_val, y_train, y_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_ZkbrxVX55c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gets training and validation splits\n",
        "X_train, X_val, y_train, y_val = shuffle_and_split()\n",
        "english_train = [x for (x, _) in X_train]\n",
        "german_train = [y for (_, y) in X_train]\n",
        "english_val = [x for (x, _) in X_val]\n",
        "german_val = [y for (_, y) in X_val]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqIdGUF3PncQ",
        "colab_type": "text"
      },
      "source": [
        "## Sentence averages to MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W2Fj1SByTGW",
        "colab_type": "text"
      },
      "source": [
        "Get embeddings and pad training and validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEugaxW4M4po",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "english_embs = get_embeddings(english_train, nlp_en, stop_words_en, 'en')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EsfqDjklLZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "english_embs = pad_sent(english_embs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci1n7f1_M5Ii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "german_embs = get_embeddings(german_train, nlp_de, stop_words_de, 'de')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYeivJdFmIpa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "german_embs = pad_sent(german_embs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhNafoaignGE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(english_embs)):\n",
        "  english_embs[i] = np.array(english_embs[i]).mean(axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6Ea7oZZp8KM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(german_embs)):\n",
        "  german_embs[i] = np.array(german_embs[i]).mean(axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gooE88NY7yM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "english_embs2 = get_embeddings(english_val, nlp_en, stop_words_en, 'en')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UYMRFX7ZAMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "german_embs2 = get_embeddings(german_val, nlp_de, stop_words_de, 'de')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw_z5m_NqH0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "english_embs2 = pad_sent(english_embs2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSehyWNFqLmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "german_embs2 = pad_sent(german_embs2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdcJQ6jtyaJS",
        "colab_type": "text"
      },
      "source": [
        "Find averages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHwRx7ycqQw2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(german_embs2)):\n",
        "  german_embs2[i] = np.array(german_embs2[i]).mean(axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3ZAL5vuqUqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(english_embs2)):\n",
        "  english_embs2[i] = np.array(english_embs2[i]).mean(axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPlVYkaQqn9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = []\n",
        "for i in range(len(english_embs)):\n",
        "  X_train.append(np.concatenate((np.array(english_embs[i]), np.array(german_embs[i]))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "447NClThrqWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_val = []\n",
        "for i in range(len(english_embs2)):\n",
        "  X_val.append(np.concatenate((np.array(english_embs2[i]), np.array(german_embs2[i]))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbMCFjUCPywc",
        "colab_type": "text"
      },
      "source": [
        "MLP Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJL1KLqKZPeN",
        "colab_type": "code",
        "outputId": "12ac28ab-15fe-42fb-f767-4add3ea638f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "m = Sequential()\n",
        "m.add(Dense(64, activation='relu', input_dim=600))\n",
        "m.add(Dense(128, activation='relu', input_dim=600))\n",
        "m.add(Dense(64, activation='relu', input_dim=600))\n",
        "m.add(Dense(1))\n",
        "m.summary()\n",
        "m.compile(loss='mse',\n",
        "    optimizer='Adam',\n",
        "    metrics=['mae'])"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 64)                38464     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 55,105\n",
            "Trainable params: 55,105\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsaiCrAwZW3A",
        "colab_type": "code",
        "outputId": "6266edef-6447-42f2-bf96-8346e37d9f44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "m.fit(np.array(X_train),np.array(y_train), epochs=10, validation_data=(np.array(X_val), y_val), verbose=1)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7000 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            "7000/7000 [==============================] - 1s 107us/step - loss: 0.6779 - mean_absolute_error: 0.4904 - val_loss: 0.7536 - val_mean_absolute_error: 0.5003\n",
            "Epoch 2/10\n",
            "7000/7000 [==============================] - 0s 65us/step - loss: 0.6703 - mean_absolute_error: 0.4879 - val_loss: 0.7549 - val_mean_absolute_error: 0.5140\n",
            "Epoch 3/10\n",
            "7000/7000 [==============================] - 0s 64us/step - loss: 0.6623 - mean_absolute_error: 0.4872 - val_loss: 0.7580 - val_mean_absolute_error: 0.4930\n",
            "Epoch 4/10\n",
            "7000/7000 [==============================] - 0s 69us/step - loss: 0.6542 - mean_absolute_error: 0.4853 - val_loss: 0.7544 - val_mean_absolute_error: 0.5172\n",
            "Epoch 5/10\n",
            "7000/7000 [==============================] - 0s 66us/step - loss: 0.6360 - mean_absolute_error: 0.4841 - val_loss: 0.7620 - val_mean_absolute_error: 0.5026\n",
            "Epoch 6/10\n",
            "7000/7000 [==============================] - 0s 64us/step - loss: 0.6167 - mean_absolute_error: 0.4814 - val_loss: 0.7792 - val_mean_absolute_error: 0.4998\n",
            "Epoch 7/10\n",
            "7000/7000 [==============================] - 0s 66us/step - loss: 0.5788 - mean_absolute_error: 0.4692 - val_loss: 0.7942 - val_mean_absolute_error: 0.5275\n",
            "Epoch 8/10\n",
            "7000/7000 [==============================] - 0s 68us/step - loss: 0.5250 - mean_absolute_error: 0.4556 - val_loss: 0.8587 - val_mean_absolute_error: 0.5467\n",
            "Epoch 9/10\n",
            "7000/7000 [==============================] - 0s 66us/step - loss: 0.4815 - mean_absolute_error: 0.4430 - val_loss: 0.8527 - val_mean_absolute_error: 0.5351\n",
            "Epoch 10/10\n",
            "7000/7000 [==============================] - 1s 72us/step - loss: 0.3963 - mean_absolute_error: 0.4140 - val_loss: 0.9546 - val_mean_absolute_error: 0.6128\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fad9a6db7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX_pea0Y36al",
        "colab_type": "code",
        "outputId": "8d011141-8def-4cc2-f071-0d31fbfe6407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pearson_score, _ = pearsonr(m.predict(np.array(X_val)).squeeze(), y_val)\n",
        "print(\"Pearson score: \", pearson_score)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pearson score:  0.06183897819343952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PhoWdE8RNF_",
        "colab_type": "text"
      },
      "source": [
        "## Parameter tuning with cross validation for LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGnOuXKSRQce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def param_tuning():\n",
        "  lstm_units = [32, 64, 128]\n",
        "  lstm_dropouts = [0.1, 0.2, 0.01]\n",
        "  dense_neurons = [[64, 128], [32, 64], [128, 256]]\n",
        "  dense_activations = [[\"relu\", \"relu\"], [\"tanh\", \"tanh\"], [\"relu\", \"tanh\"]]\n",
        "  model_id = 0\n",
        "\n",
        "  for units in lstm_units:\n",
        "    for dropout in lstm_dropouts:\n",
        "      for neurons in dense_neurons:\n",
        "        for activations in dense_activations:\n",
        "          print(dropout, neurons)\n",
        "          cross_validation(units, dropout, neurons, activations, model_id, get_embeddings)\n",
        "          model_id += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCyfSNeaYpu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_baseline_lstm_model(lstm_units=64, lstm_dropout=0.1, num_of_dense=3, dense_neurons=[64,128], dense_activations=[\"relu\", \"relu\"]):\n",
        "  # LSTM Approach\n",
        "  inputA = Input(shape=(60,300))\n",
        "  inputB = Input(shape=(60,300))\n",
        "\n",
        "  # first branch for first input\n",
        "  x = SeqSelfAttention()(inputA)\n",
        "  x = Bidirectional(LSTM(units=lstm_units, return_sequences=False, dropout=lstm_dropout))(x)\n",
        "  # second branch for second input\n",
        "  y = SeqSelfAttention()(inputB)\n",
        "  y = Bidirectional(LSTM(units=lstm_units, return_sequences=False, dropout=lstm_dropout))(y)\n",
        "  # combines the two branches\n",
        "  combined = Concatenate(axis=-1)([x, y])\n",
        "  # FC layers\n",
        "  z = Dense(dense_neurons[0], activation=dense_activations[0])(combined)\n",
        "  for i in range(1, num_of_dense - 1):\n",
        "    z = Dense(dense_neurons[i], activation=dense_activations[i])(z)\n",
        "  z = Dense(1)(z)\n",
        "\n",
        "  model = Model(inputs=[inputA, inputB], outputs=z)\n",
        "  model.summary()\n",
        "  model.compile(\n",
        "      loss='mse',\n",
        "      optimizer='Adam',\n",
        "      metrics=['mae']\n",
        "  )\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnPKZp3bRS5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cross_validation(units, dropout, neurons, activations, model_id, get_embeddings):\n",
        "  kf = KFold(n_splits=8, shuffle=False, random_state=None)\n",
        "\n",
        "  train_f_en = open('./train.ende.src')\n",
        "  lines_train_en = train_f_en.readlines()\n",
        "  train_f_de = open('./train.ende.mt')\n",
        "  lines_train_de = train_f_de.readlines()\n",
        "  val_f_en = open('./dev.ende.src')\n",
        "  lines_val_en = val_f_en.readlines()\n",
        "  val_f_de = open('./dev.ende.mt')\n",
        "  lines_val_de = val_f_de.readlines()\n",
        "  train_scores_f = open('./train.ende.scores')\n",
        "  train_scores = train_scores_f.readlines()\n",
        "  val_scores_f = open('./dev.ende.scores')\n",
        "  val_scores = val_scores_f.readlines()\n",
        "\n",
        "  # Combine training and validation data\n",
        "  data = []\n",
        "  for i in range(len(lines_train_en)):\n",
        "    data.append((lines_train_en[i], lines_train_de[i]))\n",
        "  \n",
        "  for i in range(len(lines_val_en)):\n",
        "    data.append((lines_val_en[i], lines_val_de[i]))\n",
        "\n",
        "  scores = []\n",
        "  for score in train_scores:\n",
        "    scores.append(float(score))\n",
        "  \n",
        "  for score in val_scores:\n",
        "    scores.append(float(score))\n",
        "\n",
        "  shuffle(data, scores, random_state=42)\n",
        "  \n",
        "  average_pearson = 0\n",
        "  average_mse = 0\n",
        "  split = 0\n",
        "  for train_index, val_index in kf.split(np.array(data)):\n",
        "    # Get splits\n",
        "    X_train, y_train = np.array(data)[train_index], np.array(scores)[train_index]\n",
        "    X_val, y_val = np.array(data)[val_index], np.array(scores)[val_index]\n",
        "    X_train = X_train.tolist()\n",
        "    X_val = X_val.tolist()\n",
        "    y_train = y_train.tolist()\n",
        "    y_val = y_val.tolist()\n",
        "    en_train_input = [x for (x, _) in X_train]\n",
        "    de_train_input = [y for (_, y) in X_train]\n",
        "    en_val_input = [x for (x, _) in X_val]\n",
        "    de_val_input = [y for (_, y) in X_val]\n",
        "\n",
        "    # Get embeddings\n",
        "    en_train_input = get_embeddings(en_train_input, nlp_en, stop_words_en, 'en')\n",
        "    de_train_input = get_embeddings(de_train_input, nlp_de, stop_words_de, 'de')\n",
        "    en_train_input = pad_sent(en_train_input)\n",
        "    de_train_input = pad_sent(de_train_input)\n",
        "    en_val_input = get_embeddings(en_val_input, nlp_en, stop_words_en, 'en')\n",
        "    de_val_input = get_embeddings(de_val_input, nlp_de, stop_words_de, 'de')\n",
        "    en_val_input = pad_sent(en_val_input)\n",
        "    de_val_input = pad_sent(de_val_input)\n",
        "\n",
        "    # Keep 500 samples for testing\n",
        "    X_test_en = en_val_input[500:]\n",
        "    X_test_de = de_val_input[500:]\n",
        "    y_test = y_val[500:]\n",
        "    en_val_input = en_val_input[:500]\n",
        "    de_val_input = de_val_input[:500]\n",
        "    y_val = y_val[:500]\n",
        "    \n",
        "    # Train model\n",
        "    model = get_baseline_lstm_model(lstm_units=units, lstm_dropout=dropout, dense_neurons=neurons, dense_activations=activations)\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
        "    history = model.fit([np.array(en_train_input), np.array(de_train_input)],np.array(y_train), epochs=10, validation_data=([en_val_input, de_val_input], y_val), verbose=1, batch_size=512, callbacks=[es])\n",
        "\n",
        "    # Get metrics for validation predictions\n",
        "    predictions = model.predict([np.array(X_test_en), np.array(X_test_de)])\n",
        "    (pearson, _) = pearsonr(predictions.squeeze(), y_test)\n",
        "    average_pearson += pearson\n",
        "    print(\"Pearson score: \", pearson)\n",
        "    mse, _ = model.evaluate([np.array(X_test_en), np.array(X_test_de)], y_test)\n",
        "    average_mse += mse\n",
        "    print(\"MSE: \", mse)\n",
        "    split += 1\n",
        "  print(\"Average pearson score: \", average_pearson / 8)\n",
        "  print(\"Average mse: \", average_mse / 8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYooHUjSSet6",
        "colab_type": "code",
        "outputId": "2afbb78d-816e-4a74-8668-22b8b5e95447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        }
      },
      "source": [
        "param_tuning()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1 [64, 128]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-b7a5170b15e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparam_tuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-43-132ef1c14bbb>\u001b[0m in \u001b[0;36mparam_tuning\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mactivations\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdense_activations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneurons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m           \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m           \u001b[0mmodel_id\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-9b9cfaadb64b>\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(units, dropout, neurons, activations, model_id, get_embeddings)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# Get embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0men_train_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_train_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlp_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mde_train_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde_train_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlp_de\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words_de\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'de'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0men_train_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_train_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-864c5ca5cc85>\u001b[0m in \u001b[0;36mget_embeddings\u001b[0;34m(lines, nlp, stopwords, lang)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(self, texts, as_tuples, n_threads, batch_size, disable, cleanup, component_cfg)\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0moriginal_strings_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0mnr_seen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.predict\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.greedy_parse\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mMust\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m_parser_model.pyx\u001b[0m in \u001b[0;36mspacy.syntax._parser_model.ParserModel.begin_update\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_parser_model.pyx\u001b[0m in \u001b[0;36mspacy.syntax._parser_model.ParserStepModel.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/api.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(seqs_in, drop)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseqs_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbp_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbp_layer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/resnet.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbp_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/layernorm.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mXhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackprop_rescale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_begin_update_scale_shift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfinish_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/layernorm.py\u001b[0m in \u001b[0;36m_begin_update_scale_shift\u001b[0;34m(self, input__BI)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgradient__BI\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minput__BI\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinish_update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/describe.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, type)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mi4Uzp8pQRLF",
        "colab_type": "text"
      },
      "source": [
        "## Different embeddings with LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZpqf9RXcE5k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "5983eba5-6973-4ad4-b3f4-9cee77a1d2ad"
      },
      "source": [
        "# Install FastText\n",
        "!git clone https://github.com/facebookresearch/fastText.git\n",
        "!pip install ./fastText/.\n",
        "import fasttext\n",
        "import fasttext.util"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fastText'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Counting objects:   4% (1/22)\u001b[K\rremote: Counting objects:   9% (2/22)\u001b[K\rremote: Counting objects:  13% (3/22)\u001b[K\rremote: Counting objects:  18% (4/22)\u001b[K\rremote: Counting objects:  22% (5/22)\u001b[K\rremote: Counting objects:  27% (6/22)\u001b[K\rremote: Counting objects:  31% (7/22)\u001b[K\rremote: Counting objects:  36% (8/22)\u001b[K\rremote: Counting objects:  40% (9/22)\u001b[K\rremote: Counting objects:  45% (10/22)\u001b[K\rremote: Counting objects:  50% (11/22)\u001b[K\rremote: Counting objects:  54% (12/22)\u001b[K\rremote: Counting objects:  59% (13/22)\u001b[K\rremote: Counting objects:  63% (14/22)\u001b[K\rremote: Counting objects:  68% (15/22)\u001b[K\rremote: Counting objects:  72% (16/22)\u001b[K\rremote: Counting objects:  77% (17/22)\u001b[K\rremote: Counting objects:  81% (18/22)\u001b[K\rremote: Counting objects:  86% (19/22)\u001b[K\rremote: Counting objects:  90% (20/22)\u001b[K\rremote: Counting objects:  95% (21/22)\u001b[K\rremote: Counting objects: 100% (22/22)\u001b[K\rremote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 3679 (delta 2), reused 17 (delta 1), pack-reused 3657\u001b[K\n",
            "Receiving objects: 100% (3679/3679), 8.10 MiB | 39.69 MiB/s, done.\n",
            "Resolving deltas: 100% (2313/2313), done.\n",
            "Processing ./fastText\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.1) (2.4.3)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.1) (45.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.1) (1.17.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.1-cp36-cp36m-linux_x86_64.whl size=2856297 sha256=0f00315697caa8f09620b6de64f470c0103f709a769d0eb83e6e5311674ae5fa\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-al69gyzg/wheels/a1/9f/52/696ce6c5c46325e840c76614ee5051458c0df10306987e7443\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQpWG2ttQO-9",
        "colab_type": "text"
      },
      "source": [
        "Embeddings class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytpiJTNgY6rk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Embeddings class for FastText and Muse\n",
        "class Embedding:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.ft = None\n",
        "    self.ft_de = None\n",
        "    self.nlp_de = None\n",
        "    self.nlp_en = None\n",
        "    self.wvecs = None\n",
        "    self.german_wvecs = None\n",
        "\n",
        "  def download_fast_text(self):\n",
        "    !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
        "    !gunzip cc.en.300.bin.gz\n",
        "    !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.de.300.bin.gz\n",
        "    !gunzip cc.de.300.bin.gz\n",
        "\n",
        "    self.ft = fasttext.load_model('cc.en.300.bin')\n",
        "    self.ft_de = fasttext.load_model('cc.de.300.bin')\n",
        "    fasttext.util.reduce_model(self.ft, 100)\n",
        "    self.ft.save_model('/drive/My Drive/cc.en.100.bin')\n",
        "\n",
        "    fasttext.util.reduce_model(self.ft_de, 100)\n",
        "    self.ft.save_model('drive/My Drive/cc.de.100.bin')\n",
        "\n",
        "  def load_fast_text(self):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    self.ft_en = fasttext.load_model('drive/My Drive/cc.de.100.bin')\n",
        "    self.ft_de = fasttext.load_model('drive/My Drive/cc.en.100.bin')\n",
        "\n",
        "  def load_muse(self):\n",
        "    !wget https://dl.fbaipublicfiles.com/arrival/vectors/wiki.multi.en.vec\n",
        "    !wget https://dl.fbaipublicfiles.com/arrival/vectors/wiki.multi.de.vec\n",
        "\n",
        "    self.wvecs = {}\n",
        "    with open(\"./wiki.multi.en.vec\", \"r\") as ende_src:\n",
        "      for line in ende_src:\n",
        "        word = line.split(\" \")[0]\n",
        "        vector = [float(a) for a in line.split(\" \")[1:]]\n",
        "        self.wvecs[word] = vector\n",
        "\n",
        "    self.german_wvecs = {}\n",
        "    with open(\"./wiki.multi.de.vec\", \"r\") as ende_src:\n",
        "      for line in ende_src:\n",
        "        word = line.split(\" \")[0]\n",
        "        vector = [float(a) for a in line.split(\" \")[1:]]\n",
        "        self.german_wvecs[word] = vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l1Qn3_gVZgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_fasttext_embeddings(lines, nlp, stopwords, lang):\n",
        "  unknown = nlp.vocab['unk'].vector\n",
        "  punctuation = [',','.','...','\\'', '\"', '(', ')', '[', ']']\n",
        "  lines_embs = []\n",
        "  \n",
        "  documents = nlp.pipe(lines, batch_size=32, n_threads=7)\n",
        "  embedding = Embedding()\n",
        "  embedding.load_fast_text()\n",
        "  for doc in documents:\n",
        "    embs = []\n",
        "    for token in doc:\n",
        "      if token.text in stopwords or token.text in punctuation:\n",
        "        continue\n",
        "      if lang == 'en':\n",
        "        embs.append(embedding.ft_en.get_word_vector(token.text))\n",
        "      else:\n",
        "        embs.append(embedding.ft_de.get_word_vector(token.text))\n",
        "    lines_embs.append(embs)\n",
        "  return lines_embs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MXZEOB-Qz6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_fasttext_embedding_results():\n",
        "  # Get best model\n",
        "  best_model = get_baseline_lstm_model(lstm_units=64, lstm_dropout=0.1, num_of_dense=3, dense_neurons=[64,128], dense_activations=[\"relu\", \"relu\"])\n",
        "\n",
        "  # Cross validation\n",
        "  cross_validation(64, 0.1, [64,128],['relu','relu'], 0, None, get_fasttext_embeddings)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcyzzjTRayLr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "66afebf4-db35-418b-edaf-8ff8e2d74f86"
      },
      "source": [
        "get_fasttext_embedding_results()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, ?, 100)\n",
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_15 (InputLayer)           (None, 60, 100)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_16 (InputLayer)           (None, 60, 100)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "seq_self_attention_15 (SeqSelfA (None, 60, 100)      6465        input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "seq_self_attention_16 (SeqSelfA (None, 60, 100)      6465        input_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_15 (Bidirectional (None, 128)          84480       seq_self_attention_15[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_16 (Bidirectional (None, 128)          84480       seq_self_attention_16[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 256)          0           bidirectional_15[0][0]           \n",
            "                                                                 bidirectional_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_22 (Dense)                (None, 64)           16448       concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_23 (Dense)                (None, 128)          8320        dense_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_24 (Dense)                (None, 1)            129         dense_23[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 206,787\n",
            "Trainable params: 206,787\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar."
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(?, ?, 100)\n",
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_17 (InputLayer)           (None, 60, 100)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_18 (InputLayer)           (None, 60, 100)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "seq_self_attention_17 (SeqSelfA (None, 60, 100)      6465        input_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "seq_self_attention_18 (SeqSelfA (None, 60, 100)      6465        input_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_17 (Bidirectional (None, 128)          84480       seq_self_attention_17[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_18 (Bidirectional (None, 128)          84480       seq_self_attention_18[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 256)          0           bidirectional_17[0][0]           \n",
            "                                                                 bidirectional_18[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_25 (Dense)                (None, 64)           16448       concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_26 (Dense)                (None, 128)          8320        dense_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_27 (Dense)                (None, 1)            129         dense_26[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 206,787\n",
            "Trainable params: 206,787\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 7000 samples, validate on 500 samples\n",
            "Epoch 1/10\n",
            "7000/7000 [==============================] - 31s 4ms/step - loss: 0.6925 - mean_absolute_error: 0.4923 - val_loss: 0.7539 - val_mean_absolute_error: 0.5342\n",
            "Epoch 2/10\n",
            "7000/7000 [==============================] - 21s 3ms/step - loss: 0.6897 - mean_absolute_error: 0.4893 - val_loss: 0.7527 - val_mean_absolute_error: 0.5316\n",
            "Epoch 3/10\n",
            "7000/7000 [==============================] - 21s 3ms/step - loss: 0.6873 - mean_absolute_error: 0.4898 - val_loss: 0.7543 - val_mean_absolute_error: 0.5308\n",
            "Epoch 00003: early stopping\n",
            "Pearson score:  0.0910126731455041\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "MSE:  0.5734901149272918\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar."
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(?, ?, 100)\n",
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_19 (InputLayer)           (None, 60, 100)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_20 (InputLayer)           (None, 60, 100)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "seq_self_attention_19 (SeqSelfA (None, 60, 100)      6465        input_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "seq_self_attention_20 (SeqSelfA (None, 60, 100)      6465        input_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_19 (Bidirectional (None, 128)          84480       seq_self_attention_19[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_20 (Bidirectional (None, 128)          84480       seq_self_attention_20[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 256)          0           bidirectional_19[0][0]           \n",
            "                                                                 bidirectional_20[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_28 (Dense)                (None, 64)           16448       concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_29 (Dense)                (None, 128)          8320        dense_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_30 (Dense)                (None, 1)            129         dense_29[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 206,787\n",
            "Trainable params: 206,787\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 7000 samples, validate on 500 samples\n",
            "Epoch 1/10\n",
            "7000/7000 [==============================] - 30s 4ms/step - loss: 0.6919 - mean_absolute_error: 0.4924 - val_loss: 0.6977 - val_mean_absolute_error: 0.4838\n",
            "Epoch 2/10\n",
            "7000/7000 [==============================] - 21s 3ms/step - loss: 0.6886 - mean_absolute_error: 0.4898 - val_loss: 0.6928 - val_mean_absolute_error: 0.4876\n",
            "Epoch 3/10\n",
            "7000/7000 [==============================] - 21s 3ms/step - loss: 0.6833 - mean_absolute_error: 0.4924 - val_loss: 0.6877 - val_mean_absolute_error: 0.4859\n",
            "Epoch 4/10\n",
            "7000/7000 [==============================] - 21s 3ms/step - loss: 0.6789 - mean_absolute_error: 0.4933 - val_loss: 0.6933 - val_mean_absolute_error: 0.4787\n",
            "Epoch 00004: early stopping\n",
            "Pearson score:  0.05532831368939686\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "MSE:  0.6438159401416779\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar."
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(?, ?, 100)\n",
            "Model: \"model_11\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_21 (InputLayer)           (None, 60, 100)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_22 (InputLayer)           (None, 60, 100)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "seq_self_attention_21 (SeqSelfA (None, 60, 100)      6465        input_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "seq_self_attention_22 (SeqSelfA (None, 60, 100)      6465        input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_21 (Bidirectional (None, 128)          84480       seq_self_attention_21[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_22 (Bidirectional (None, 128)          84480       seq_self_attention_22[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 256)          0           bidirectional_21[0][0]           \n",
            "                                                                 bidirectional_22[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_31 (Dense)                (None, 64)           16448       concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_32 (Dense)                (None, 128)          8320        dense_31[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_33 (Dense)                (None, 1)            129         dense_32[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 206,787\n",
            "Trainable params: 206,787\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 7000 samples, validate on 500 samples\n",
            "Epoch 1/10\n",
            "7000/7000 [==============================] - 32s 5ms/step - loss: 0.6690 - mean_absolute_error: 0.4852 - val_loss: 0.9129 - val_mean_absolute_error: 0.5500\n",
            "Epoch 2/10\n",
            "7000/7000 [==============================] - 21s 3ms/step - loss: 0.6679 - mean_absolute_error: 0.4910 - val_loss: 0.9199 - val_mean_absolute_error: 0.5410\n",
            "Epoch 00002: early stopping\n",
            "Pearson score:  0.028032273535856782\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "MSE:  0.7571232818365097\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(?, ?, 100)\n",
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_23 (InputLayer)           (None, 60, 100)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_24 (InputLayer)           (None, 60, 100)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "seq_self_attention_23 (SeqSelfA (None, 60, 100)      6465        input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "seq_self_attention_24 (SeqSelfA (None, 60, 100)      6465        input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_23 (Bidirectional (None, 128)          84480       seq_self_attention_23[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_24 (Bidirectional (None, 128)          84480       seq_self_attention_24[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 256)          0           bidirectional_23[0][0]           \n",
            "                                                                 bidirectional_24[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_34 (Dense)                (None, 64)           16448       concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_35 (Dense)                (None, 128)          8320        dense_34[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_36 (Dense)                (None, 1)            129         dense_35[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 206,787\n",
            "Trainable params: 206,787\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 7000 samples, validate on 500 samples\n",
            "Epoch 1/10\n",
            "7000/7000 [==============================] - 33s 5ms/step - loss: 0.7002 - mean_absolute_error: 0.5006 - val_loss: 0.6327 - val_mean_absolute_error: 0.4717\n",
            "Epoch 2/10\n",
            "7000/7000 [==============================] - 21s 3ms/step - loss: 0.6984 - mean_absolute_error: 0.4980 - val_loss: 0.6367 - val_mean_absolute_error: 0.4849\n",
            "Epoch 00002: early stopping\n",
            "Pearson score:  0.06561758518020848\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "MSE:  0.603040390253067\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(?, ?, 100)\n",
            "Model: \"model_13\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_25 (InputLayer)           (None, 60, 100)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_26 (InputLayer)           (None, 60, 100)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "seq_self_attention_25 (SeqSelfA (None, 60, 100)      6465        input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "seq_self_attention_26 (SeqSelfA (None, 60, 100)      6465        input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_25 (Bidirectional (None, 128)          84480       seq_self_attention_25[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_26 (Bidirectional (None, 128)          84480       seq_self_attention_26[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 256)          0           bidirectional_25[0][0]           \n",
            "                                                                 bidirectional_26[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_37 (Dense)                (None, 64)           16448       concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_38 (Dense)                (None, 128)          8320        dense_37[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_39 (Dense)                (None, 1)            129         dense_38[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 206,787\n",
            "Trainable params: 206,787\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 7000 samples, validate on 500 samples\n",
            "Epoch 1/10\n",
            "7000/7000 [==============================] - 34s 5ms/step - loss: 0.7067 - mean_absolute_error: 0.5029 - val_loss: 0.5862 - val_mean_absolute_error: 0.4599\n",
            "Epoch 2/10\n",
            "7000/7000 [==============================] - 21s 3ms/step - loss: 0.7041 - mean_absolute_error: 0.5021 - val_loss: 0.5866 - val_mean_absolute_error: 0.4592\n",
            "Epoch 00002: early stopping\n",
            "Pearson score:  0.1472438791326976\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "MSE:  0.5418383717536926\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-5608b97832d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_fasttext_embedding_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-48-94568bb53cd1>\u001b[0m in \u001b[0;36mget_fasttext_embedding_results\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# Cross validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_fasttext_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-46-c124e1a666fa>\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(units, dropout, neurons, activations, model_id, f, get_embeddings)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# Get embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0men_train_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_train_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlp_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mde_train_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde_train_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlp_de\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words_de\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'de'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0men_train_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_train_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mde_train_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde_train_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-c348b09efc6f>\u001b[0m in \u001b[0;36mget_fasttext_embeddings\u001b[0;34m(lines, nlp, stopwords, lang)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_fast_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0membs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(self, texts, as_tuples, n_threads, batch_size, disable, cleanup, component_cfg)\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0moriginal_strings_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0mnr_seen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mminibatch\u001b[0;34m(items, size)\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mminibatch\u001b[0;34m(items, size)\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpipes.pyx\u001b[0m in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpipes.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.pipes.Tagger.predict\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mMust\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/api.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(seqs_in)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseqs_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mMust\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/check.py\u001b[0m in \u001b[0;36mchecked_function\u001b[0;34m(wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mExpectedTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Callable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfix_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0marg_check_adder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/softmax.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input__BI)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nB\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"nI\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput__BI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moutput__BO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput__BI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput__BO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput__BO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkqBmWNsypaD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "2851ad89-9d99-47b8-d31f-3329529a8b4a"
      },
      "source": [
        "!pip install bert-embedding"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-embedding in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: typing==3.6.6 in /usr/local/lib/python3.6/dist-packages (from bert-embedding) (3.6.6)\n",
            "Requirement already satisfied: mxnet==1.4.0 in /usr/local/lib/python3.6/dist-packages (from bert-embedding) (1.4.0)\n",
            "Requirement already satisfied: numpy==1.14.6 in /usr/local/lib/python3.6/dist-packages (from bert-embedding) (1.14.6)\n",
            "Requirement already satisfied: gluonnlp==0.6.0 in /usr/local/lib/python3.6/dist-packages (from bert-embedding) (0.6.0)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet==1.4.0->bert-embedding) (2.21.0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet==1.4.0->bert-embedding) (0.8.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet==1.4.0->bert-embedding) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet==1.4.0->bert-embedding) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet==1.4.0->bert-embedding) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet==1.4.0->bert-embedding) (2019.11.28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOzSGdsxy4YR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bert_embedding import BertEmbedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ8KxH3EVchI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_bert_embeddings(lines, nlp, stopwords, lang):\n",
        "  unknown = nlp.vocab['unk'].vector\n",
        "  punctuation = [',','.','...','\\'', '\"', '(', ')', '[', ']']\n",
        "  lines_embs = []\n",
        "\n",
        "  documents = nlp.pipe(lines, batch_size=32, n_threads=7)\n",
        "  embedding = BertEmbedding(model='bert_12_768_12', dataset_name='wiki_multilingual')\n",
        "  for doc in documents:\n",
        "    l = []\n",
        "    embs = []\n",
        "    for token in doc:\n",
        "      if token.text in stopwords or token.text in punctuation:\n",
        "        continue\n",
        "      l.append(token.text)\n",
        "    lines_embs.append(l)\n",
        "  \n",
        "  new_lines = []\n",
        "  for line in lines_embs:\n",
        "    line = \" \".join([w for w in line])\n",
        "    new_lines.append(line)\n",
        "\n",
        "  bert_res = embedding(new_lines)\n",
        "  res = [emb for (_,emb) in bert_res]\n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI4Ki4kXRRWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_bert_embedding_results():\n",
        "  # Get best model\n",
        "  best_model = get_baseline_lstm_model(lstm_units=64, lstm_dropout=0.1, num_of_dense=3, dense_neurons=[64,128], dense_activations=[\"relu\", \"relu\"])\n",
        "\n",
        "  # Cross validation\n",
        "  cross_validation(64,0.1,[64,128],['relu','relu'], 0, None, get_bert_embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-4uaZR2z30n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f549bba0-2a5a-4eb7-f778-b731163eb759"
      },
      "source": [
        "get_bert_embedding_results()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, ?, 768)\n",
            "Model: \"model_15\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_29 (InputLayer)           (None, 60, 768)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_30 (InputLayer)           (None, 60, 768)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "seq_self_attention_29 (SeqSelfA (None, 60, 768)      49217       input_29[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "seq_self_attention_30 (SeqSelfA (None, 60, 768)      49217       input_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_29 (Bidirectional (None, 128)          426496      seq_self_attention_29[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_30 (Bidirectional (None, 128)          426496      seq_self_attention_30[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 256)          0           bidirectional_29[0][0]           \n",
            "                                                                 bidirectional_30[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_43 (Dense)                (None, 64)           16448       concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_44 (Dense)                (None, 128)          8320        dense_43[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_45 (Dense)                (None, 1)            129         dense_44[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 976,323\n",
            "Trainable params: 976,323\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Vocab file is not found. Downloading.\n",
            "Downloading /root/.mxnet/models/wiki_multilingual-2b2514cc.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/vocab/wiki_multilingual-2b2514cc.zip...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gluonnlp/model/bert.py:693: UserWarning: wiki_cn/wiki_multilingual will be deprecated. Please use wiki_cn_cased/wiki_multilingual_uncased instead.\n",
            "  warnings.warn('wiki_cn/wiki_multilingual will be deprecated.'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading /root/.mxnet/models/bert_12_768_12_wiki_multilingual-237f3985.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/bert_12_768_12_wiki_multilingual-237f3985.zip...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gluonnlp/model/bert.py:693: UserWarning: wiki_cn/wiki_multilingual will be deprecated. Please use wiki_cn_cased/wiki_multilingual_uncased instead.\n",
            "  warnings.warn('wiki_cn/wiki_multilingual will be deprecated.'\n",
            "/usr/local/lib/python3.6/dist-packages/gluonnlp/model/bert.py:693: UserWarning: wiki_cn/wiki_multilingual will be deprecated. Please use wiki_cn_cased/wiki_multilingual_uncased instead.\n",
            "  warnings.warn('wiki_cn/wiki_multilingual will be deprecated.'\n",
            "/usr/local/lib/python3.6/dist-packages/gluonnlp/model/bert.py:693: UserWarning: wiki_cn/wiki_multilingual will be deprecated. Please use wiki_cn_cased/wiki_multilingual_uncased instead.\n",
            "  warnings.warn('wiki_cn/wiki_multilingual will be deprecated.'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(?, ?, 768)\n",
            "Model: \"model_16\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_31 (InputLayer)           (None, 60, 768)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_32 (InputLayer)           (None, 60, 768)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "seq_self_attention_31 (SeqSelfA (None, 60, 768)      49217       input_31[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "seq_self_attention_32 (SeqSelfA (None, 60, 768)      49217       input_32[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_31 (Bidirectional (None, 128)          426496      seq_self_attention_31[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_32 (Bidirectional (None, 128)          426496      seq_self_attention_32[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 256)          0           bidirectional_31[0][0]           \n",
            "                                                                 bidirectional_32[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_46 (Dense)                (None, 64)           16448       concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_47 (Dense)                (None, 128)          8320        dense_46[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_48 (Dense)                (None, 1)            129         dense_47[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 976,323\n",
            "Trainable params: 976,323\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc30IDF6jVBN",
        "colab_type": "text"
      },
      "source": [
        "## Best LSTM model training and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNl6EGuMjctv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "4cc3df43-d8a3-4eea-e16c-0abd4dc179c6"
      },
      "source": [
        "# Get training and validation embeddings\n",
        "lines_en = open('./train.ende.src').readlines()\n",
        "lines_de = open('./train.ende.mt').readlines()\n",
        "\n",
        "english_train_embeddings = get_embeddings(lines_en, nlp_en, stop_words_en, 'en')\n",
        "german_train_embeddings = get_embeddings(lines_de, nlp_de, stop_words_de, 'de')\n",
        "\n",
        "scores_train = get_scores('./train.ende.scores')\n",
        "\n",
        "english_val_embeddings = get_embeddings(open('./dev.ende.src').readlines(), nlp_en, stop_words_en, 'en')\n",
        "german_val_embeddings = get_embeddings(open('./dev.ende.mt').readlines(), nlp_de, stop_words_de, 'de')\n",
        "\n",
        "scores_val = get_scores('./dev.ende.scores')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-df982f531a9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlines_en\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./train.ende.src'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlines_de\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./train.ende.mt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0menglish_train_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlp_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgerman_train_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines_de\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlp_de\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words_de\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'de'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './train.ende.src'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTo6EScf0NV1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "0abcb37e-d108-472c-871b-176702606bd9"
      },
      "source": [
        "best_model = get_baseline_lstm_model(lstm_units=64, lstm_dropout=0.1, num_of_dense=3, dense_neurons=[64,128], dense_activations=[\"relu\", \"relu\"])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, ?, 300)\n",
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            (None, 60, 300)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            (None, 60, 300)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "seq_self_attention_7 (SeqSelfAt (None, 60, 300)      19265       input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "seq_self_attention_8 (SeqSelfAt (None, 60, 300)      19265       input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_7 (Bidirectional) (None, 128)          186880      seq_self_attention_7[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_8 (Bidirectional) (None, 128)          186880      seq_self_attention_8[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 256)          0           bidirectional_7[0][0]            \n",
            "                                                                 bidirectional_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 64)           16448       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 128)          8320        dense_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 1)            129         dense_11[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 437,187\n",
            "Trainable params: 437,187\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCPqt-AKnZND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "english_train_embeddings = pad_sent(english_train_embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09oSpVlfngFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "german_train_embeddings = pad_sent(german_train_embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgbN4rXRoFHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "english_val_embeddings = pad_sent(english_val_embeddings)\n",
        "german_val_embeddings = pad_sent(german_val_embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSm8x8HHjZBY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "outputId": "c07ae4e2-9246-4366-cd5b-3c86a5ee60f9"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
        "history = best_model.fit([np.array(english_train_embeddings), np.array(german_train_embeddings)],np.array(scores_train), epochs=10, validation_data=([english_val_embeddings[:500], german_val_embeddings[:500]], scores_val[:500]), verbose=1, batch_size=1024, callbacks=[es])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7000 samples, validate on 500 samples\n",
            "Epoch 1/10\n",
            "7000/7000 [==============================] - 37s 5ms/step - loss: 0.6800 - mean_absolute_error: 0.4945 - val_loss: 0.8900 - val_mean_absolute_error: 0.5609\n",
            "Epoch 2/10\n",
            "1024/7000 [===>..........................] - ETA: 25s - loss: 0.7813 - mean_absolute_error: 0.5025"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-a75e572852f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menglish_train_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgerman_train_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menglish_val_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgerman_val_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lvLO4trpdbm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "49e25990-b61c-4e59-ab4f-9812ae79bbb2"
      },
      "source": [
        "pearsonr(best_model.predict([np.array(english_val_embeddings[500:]), np.array(german_val_embeddings[500:])]).squeeze(), np.array(scores_val[500:]))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.05890508380851993, 0.18850886823664142)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvGn_HbJXQkM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "be9ef46f-08c2-4224-9bcf-5190fcb1aab6"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "# plt.show()\n",
        "plt.savefig('loss.png')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHvGTcSGozwW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get test embeddings\n",
        "english_test_embeddings = get_embeddings(open('./test.ende.src').readlines(), nlp_en, stop_words_en, 'en')\n",
        "english_test_embeddings = pad_sent(english_test_embeddings)\n",
        "german_test_embeddings = get_embeddings(open('./test.ende.mt').readlines(), nlp_de, stop_words_de, 'de')\n",
        "german_test_embeddings = pad_sent(german_test_embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU30fRZSl7gu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_test = model.predict([np.array(english_test_embeddings), np.array(german_test_embeddings)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4OygMp-pcRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open(\"predictions.txt\", \"w\")\n",
        "for num in predictions_test:\n",
        "  f.write(f\"{num[0]}\\n\")\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}